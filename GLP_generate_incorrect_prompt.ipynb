{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "26aLwJHHKYgk",
        "iU32o9mbJa4m",
        "zQ8ZI5dHJn2g",
        "wrOUsF8kJttp",
        "v5ervOX3KCu4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "DfZH8huW2tm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "all general functions can be declared here"
      ],
      "metadata": {
        "id": "nTsDYdnR3aIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_nuQnuE2vFp",
        "outputId": "86c09e85-5d7d-47cd-f070-2635f11671c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/umd-huang-lab/Mementos.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ5QR7-n9qZI",
        "outputId": "d54e3f98-0159-494c-a32f-4cdc79e18f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mementos'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 56 (delta 23), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (56/56), 144.09 KiB | 3.60 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "9_VPZgQk4EzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MEMENTOS_DATA_DIR = \"\" # replace it with your path\n",
        "MEMENTOS_DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/Grounded Language Processing [146078]/Projects/DATA/\""
      ],
      "metadata": {
        "id": "IDKkt7DA2zX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1aXwweL9pmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Our Dataset"
      ],
      "metadata": {
        "id": "p9cAh0cO80Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to make sure that the top 100 of sequential and combined dataset has the same name. If it has the same names, it means that it depicts the same scene and is consistent"
      ],
      "metadata": {
        "id": "3OXJhn_sGwof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_SAMPLED = 100\n",
        "N_INCORRECT = 30\n",
        "\n",
        "# set the folder of combined & sequential daily life dataset\n",
        "ALL_COMB_DAILYLIFE_DIR = os.path.join(MEMENTOS_DATA_DIR, \"image_dailylife/image\")\n",
        "ALL_SEQ_DAILYLIFE_DIR = os.path.join(MEMENTOS_DATA_DIR, \"single_image_dailylife/single_image\")\n",
        "\n",
        "ALL_COMB_DAILYLIFE_FILES = os.listdir(ALL_COMB_DAILYLIFE_DIR)\n",
        "ALL_COMB_DAILYLIFE_FILES = [f for f in sorted(ALL_COMB_DAILYLIFE_FILES) if f.endswith(\".png\")]\n",
        "ALL_SEQ_DAILYLIFE_FOLDERS = os.listdir(ALL_SEQ_DAILYLIFE_DIR)\n",
        "ALL_SEQ_DAILYLIFE_FOLDERS = sorted(ALL_SEQ_DAILYLIFE_FOLDERS)\n",
        "\n",
        "# [COMBINED DATASET]\n",
        "# sampled: we want to reduce the size for this project, which is using only top 100 sequences available on the dataset\n",
        "# incorrect: the pool to pick image/sequence as incorrect pertubation/noise to our sampled dataset. we picked the last 30 sequences for this purpose\n",
        "COMB_SAMPLED_DATASET = [os.path.join(ALL_COMB_DAILYLIFE_DIR, filename) for filename in ALL_COMB_DAILYLIFE_FILES[:N_SAMPLED]]\n",
        "COMB_INCORRECT_DATASET = [os.path.join(ALL_COMB_DAILYLIFE_DIR, filename) for filename in ALL_COMB_DAILYLIFE_FILES[-N_INCORRECT:]]\n",
        "\n",
        "# [SEQUENTIAL DATASET]\n",
        "# sampled: we want to reduce the size for this project, which is using only top 100 sequences available on the dataset\n",
        "# incorrect: the pool to pick image/sequence as incorrect pertubation/noise to our sampled dataset. we picked the last 30 sequences for this purpose\n",
        "SEQ_SAMPLED_DATASET = [os.path.join(ALL_SEQ_DAILYLIFE_DIR, filename) for filename in ALL_SEQ_DAILYLIFE_FOLDERS[:N_SAMPLED]]\n",
        "SEQ_INCORRECT_DATASET = [os.path.join(ALL_SEQ_DAILYLIFE_DIR, filename) for filename in ALL_SEQ_DAILYLIFE_FOLDERS[-N_INCORRECT:]]"
      ],
      "metadata": {
        "id": "0-bUP9e93NrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure the combined & sequence dataset is consistent\n",
        "\n",
        "def check_consistency(c_dataset, s_dataset):\n",
        "  try:\n",
        "    for i, path in enumerate(c_dataset):\n",
        "      combined_filename = path.split(\"/\")[-1].replace(\".png\", \"\")\n",
        "      sequential_folder = s_dataset[i].split(\"/\")[-1]\n",
        "      if  combined_filename != sequential_folder:\n",
        "        raise Exception\n",
        "  except Exception:\n",
        "    print(f\"[ERROR INCONSISTENCY FOUND] combined_filename: {combined_filename}, sequential_folder: {sequential_folder}\")\n",
        "\n",
        "check_consistency(COMB_SAMPLED_DATASET, SEQ_SAMPLED_DATASET)\n",
        "check_consistency(COMB_INCORRECT_DATASET, SEQ_INCORRECT_DATASET)"
      ],
      "metadata": {
        "id": "G8JNjG477Wk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Incorrect Information"
      ],
      "metadata": {
        "id": "rrI9ZPkV89_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The incorrect information will be generated by MMLM using the combined input then later manually fixed in order to make sure the generated hallucinated information and ground truth contradict the image content. To create a high-quality list of hallucinations, we use Gemini and GPT-4 as MMLMs, allowing us to have an option between the outputs. <br>\n",
        "\n",
        "The hallucinated informations we generated consist of:\n",
        "- hallucinated object keyword list (generated by task 1)\n",
        "- hallucinated action/behaviour keyword list (generated by task 2)\n",
        "- generated description containing both hallucinated objects & actions (generated by task 3)"
      ],
      "metadata": {
        "id": "TgLsqnRx9C7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the task 1 actually is inspired from the Mementos paper particularly by the evaluation approach in [here](https://github.com/umd-huang-lab/Mementos/blob/main/GPT-4-assisted_evaluation.ipynb). The idea remains the same, but since the Mementos did not provide with the extracted keywords, we ran the exact prompt used in the code mentioned above to generate them. This allows us to use the keywords for the next tasks."
      ],
      "metadata": {
        "id": "wDDavR3GLbyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the prompt from task 1, we adapted the prompts so that we can use it for task 2 & 3"
      ],
      "metadata": {
        "id": "XsMDKi6cMiQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "- [create google api key](https://aistudio.google.com/app/u/6/apikey)\n",
        "- [example notebook from Gemini](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/templates/aistudio_gemini_prompt_freeform.ipynb#templateParams=%7B%22model%22%3A%22gemini-1.5-flash%22%2C%22generation_config_b64%22%3A%22eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9%22%2C%22user_input_b64%22%3A%22SU5TRVJUX0lOUFVUX0hFUkU%3D%22%2C%22contents_b64%22%3A%22W10%3D%22%7D&importGeminiApiKey=true&sandboxMode=true&scrollTo=yoL3p3KPylFW) (not a good guide)\n",
        "- [Gemini API Documentation](https://ai.google.dev/api/generate-content?authuser=6#image)"
      ],
      "metadata": {
        "id": "1_ZsKPMuBN2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from string import Template\n",
        "from google.colab import userdata\n",
        "import ast\n",
        "import time\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "9AzcvwEMD5-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\"\n",
        "!pip install -U -q \"openai==0.28\""
      ],
      "metadata": {
        "id": "kOysP_s0BUZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a18d364-cd6b-42cc-9d9a-8702793077c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GEMINI_MODEL_NAME = \"gemini-1.5-flash\"\n",
        "gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=gemini_api_key)\n",
        "\n",
        "model = genai.GenerativeModel(GEMINI_MODEL_NAME)"
      ],
      "metadata": {
        "id": "xW7bK3RjBWys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Define a reusable function\n",
        "def generate_chat_response(message, temperature=0, max_tokens=1000):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": []}\n",
        "    ]\n",
        "\n",
        "    messages[0][\"content\"].append({\n",
        "        \"type\": \"text\",\n",
        "        \"text\": message})\n",
        "\n",
        "    return openai.ChatCompletion.create(\n",
        "        model=\"gpt-4-1106-preview\",  # Set the default model here\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )"
      ],
      "metadata": {
        "id": "CMmCfIvwysmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dl_description.csv` serves as a file that contains ground truth"
      ],
      "metadata": {
        "id": "-yEVGzPyIp6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DESC_PATH = \"/content/Mementos/dl_description.csv\"\n",
        "desc_df = pd.read_csv(DESC_PATH,  encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "N4M-2Sb29JvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_list = [filename.split(\"/\")[-1] for filename in COMB_SAMPLED_DATASET]\n",
        "filtered_desc_df = desc_df[desc_df[\"image_name\"].isin(filename_list)]"
      ],
      "metadata": {
        "id": "RUofOMOQ-Dck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_desc_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs120dqR-hEW",
        "outputId": "06427dd0-35d0-406c-b068-fd588b43f42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_desc_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V2tuyhHf-jBQ",
        "outputId": "727fa26d-7ce9-41a4-b177-36e6ddd87aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           image_name                                        description\n",
              "0  rw_10011555465.png  The image captures a sequence of movements fro...\n",
              "1  rw_10111267264.png  The image shows five children standing in a li...\n",
              "2  rw_10186675055.png  The series of images captures a young girl in ...\n",
              "3  rw_10192494165.png  In the image, two children are seated at the b...\n",
              "4  rw_10289713176.png  In the series of images, we see a man in black..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3549d6ec-fd22-4e63-85cc-b63a9644495c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rw_10011555465.png</td>\n",
              "      <td>The image captures a sequence of movements fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rw_10111267264.png</td>\n",
              "      <td>The image shows five children standing in a li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rw_10186675055.png</td>\n",
              "      <td>The series of images captures a young girl in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rw_10192494165.png</td>\n",
              "      <td>In the image, two children are seated at the b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rw_10289713176.png</td>\n",
              "      <td>In the series of images, we see a man in black...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3549d6ec-fd22-4e63-85cc-b63a9644495c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3549d6ec-fd22-4e63-85cc-b63a9644495c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3549d6ec-fd22-4e63-85cc-b63a9644495c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4fbcc99e-2a60-452d-9a56-59599e154f67\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fbcc99e-2a60-452d-9a56-59599e154f67')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4fbcc99e-2a60-452d-9a56-59599e154f67 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_desc_df",
              "summary": "{\n  \"name\": \"filtered_desc_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"rw_2937016891.png\",\n          \"rw_2549562657.png\",\n          \"rw_2738131533.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"In the series of images, we see a man and a young girl spending time in a park with their dog. The man is holding a plastic bag in his right hand while walking the dog, which is on a leash. The girl, dressed in blue, is seen bending down to play with the dog at one point. When the dog jumps towards her, she holds its legs. After playing with the girl, the dog runs back to the man. The images capture a leisurely and playful moment between the two individuals and their pet in an outdoor setting.\",\n          \"In the living room, a group of children are gathered around a mat, playing with an assortment of toys scattered across the mat and the floor, provided for their entertainment. A baby dressed in a black shirt is sitting upright, while another baby, wearing blue and red stripes, is lying down amidst the playful chaos and is curiously interacting with a blue ball by biting it. Adults are present in the background, attentively watching over the children to ensure their safety and care as they enjoy their playtime.\",\n          \"The images depict a sequence of events during a puppet show aimed at entertaining children. The performance features a lady with blonde hair who is actively engaging with the puppet, including a moment where she raises her hands and shouts. At one point, the puppet gives toys after handing a purple toy to the lady. During the performance, she moves closer to the puppet, seemingly attempting to take a toy, and claps her hands in reaction to the unfolding events. The children in the audience, follow the lady's lead. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# later we will export this as csv\n",
        "result = {\n",
        "    \"object_list\": [],\n",
        "    \"action_list\": [],\n",
        "    \"hallucinated_object_list\": [],\n",
        "    \"hallucinated_action_list\": [],\n",
        "    \"incorrect_description\": []\n",
        "}"
      ],
      "metadata": {
        "id": "6_Ip3lQqEQbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INCORRECT_DESC_PATH = \"\" # replace it with your path\n",
        "INCORRECT_DESC_PATH = \"/content/drive/MyDrive/Colab Notebooks/Grounded Language Processing [146078]/Projects/incorrect_description.csv\""
      ],
      "metadata": {
        "id": "7i_ei-Rnah5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw_extraction_template = Template(\"Please extract the object and action words or phrases from the following text. The objects should have a tangible meaning and consist of no more than two words; non-tangible objects should not be extracted. The action words or phrases should only relate to the extracted objects. Also, you must convert the corresponding actions to their complete root form. Please directly output the final object and action lists.\\nHere is an example:\\n The sequence of images captures a dog's cautious interaction with a metal toy inside a house. The dog appears wary and maintains a distance from the unfamiliar object, barking to express its disapproval and possibly intimidation. As the toy moves, the dog's reaction is to bark and lean backward, showing a clear sign of being unsettled by the toy's motion. When the toy momentarily ceases movement, the dog also stops, remaining alert and attentive. At the end of the image, when the toy comes to a halt, the dog looks up, still processing the strange encounter with the inanimate object.\\nThe lists are\\nObject list: [dog, toy, house]\\nAction list: [interaction, bark, express intimidation, move, lean backward, stop, look up]\\nHere is the paragraph:\\n $gt_desc. \\nThe lists are:\")\n",
        "kw_hallucinate_template = Template(\"The given lists are object list and action list consecutively. Please create a hallucinated list that contains object words that are not related with the given object list and a hallucinated list that contains action words that are not related with the given action list. However, I want the hallucinated object list still corresponds with the hallucinated action list, which means the objects in the hallucinated object list can do the actions in hallucinated action list. Also, you must convert the hallucinated actions to their complete root form.\\nThe lists generated must be in list format [item1, item2, item3].\\n For example the lists are\\nObject list: [dog, toy, house]\\nAction list: [interaction, bark, express intimidation, move, lean backward, stop, look up]\\nThe hallucinated lists are:\\nObject list: [cat, sofa, ball]\\nAction list: [play, nap, land, turn left]\\nHere are the given lists:\\nObject list:\\n $object_list\\n Action list:\\n $action_list. \\nThe hallucinated lists are:\")\n",
        "incorrect_desc_template = Template(\"Please create a paragraph based on given object list and action list. The objects in the object list do the actions in action list. The action in the action list are in the root form. You can convert it into any tense form, the only condition is that the object and action are connected in plausible way.\\nFor example the lists are\\nObject list: [dog, toy, house]\\nAction list: [interaction, bark, express intimidation, move, lean backward, stop, look up]\\nThe generated paragraph is:\\nThe sequence of images captures a dog's cautious interaction with a metal toy inside a house. The dog appears wary and maintains a distance from the unfamiliar object, barking to express its disapproval and possibly intimidation. As the toy moves, the dog's reaction is to bark and lean backward, showing a clear sign of being unsettled by the toy's motion. When the toy momentarily ceases movement, the dog also stops, remaining alert and attentive. At the end of the image, when the toy comes to a halt, the dog looks up, still processing the strange encounter with the inanimate object.\\nHere are the given lists:\\nObject list:\\n $object_list\\n Action list:\\n $action_list. \\nThe paragraph is:\")"
      ],
      "metadata": {
        "id": "4b8Bn7z2_dyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare the Regex Function"
      ],
      "metadata": {
        "id": "26aLwJHHKYgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# this pattern is used to capture list in a string. for example \"[dog, toy, house]\"\n",
        "list_pattern = re.compile(r\"\\[([^\\]]*)\\]\")"
      ],
      "metadata": {
        "id": "0KslIgzeJLRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a precautions, in case that the MMLMs have difficulty in parsing the list, which is why we provided the function to clean the apostrophe in a string of list. This function can be used when/if needed"
      ],
      "metadata": {
        "id": "CBjN8ktoKqZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "since the string can be ['robot arm', 'telescope', 'dancer's legs', 'puppet']\n",
        "it will be a problem to convert from a string to a list because an apostrophe inside the word (eg. 'dancer's legs')\n",
        "the 's make the case tricky as `ast` library will think it is the end of the word, but it isn't.\n",
        "\n",
        "so, we would like to convert the string to [\"robot arm\", \"telescope\", \"dancer's legs\", \"puppet\"]\n",
        "to make sure ast library works correctly\n",
        "\n",
        "what we want to do, replace ' in these locations:\n",
        "# 1. After a [ or a comma\n",
        "# 2. Before a ]\n",
        "\"\"\"\n",
        "uniquote_pattern = re.compile(r\"\\[(')|(')\\,\\s?(')|(')\\]\")"
      ],
      "metadata": {
        "id": "pBgA4CdiKpxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text with single quotes inside list items\n",
        "text = \"**Hallucinated Object List:** ['robot arm', 'telescope', 'dancer's legs', 'puppet']\"\n",
        "\n",
        "# Function to replace single quotes with double quotes\n",
        "def replace_groups(match):\n",
        "    # Replace the single quote in the matched group with double quotes\n",
        "    if match.group(1) == \"'\":\n",
        "      return '[\"'\n",
        "    if match.group(2) == \"'\" and match.group(3) == \"'\":\n",
        "      return '\", \"'\n",
        "    if match.group(4) == \"'\":\n",
        "      return '\"]'\n",
        "    else:\n",
        "      return match.group(0)\n",
        "\n",
        "# Replace single quotes with double quotes\n",
        "formatted_text = uniquote_pattern.sub(replace_groups, text)\n",
        "\n",
        "print(formatted_text)\n",
        "\n",
        "# h_object_list = uniquote_pattern.sub(replace_groups, h_object_list)\n",
        "# h_object_list = ast.literal_eval(h_object_list)\n",
        "# h_action_list = uniquote_pattern.sub(replace_groups, h_action_list)\n",
        "# h_action_list = ast.literal_eval(h_action_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2up9XRqPKHr",
        "outputId": "e5f0e086-d484-4179-abd1-9ece30494d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Hallucinated Object List:** [\"robot arm\", \"telescope\", \"dancer's legs\", \"puppet\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Keyword Extraction (inspired by the Mementos paper)"
      ],
      "metadata": {
        "id": "iU32o9mbJa4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for desc in tqdm(filtered_desc_df[\"description\"].tolist(), \"keyword extraction\"):\n",
        "  # gemini\n",
        "  # response = model.generate_content([kw_extraction_template.substitute(gt_desc=desc)])\n",
        "  # response = response.text.split(\"\\n\")\n",
        "\n",
        "  # chat-gpt\n",
        "  object_list, action_list = [], []\n",
        "  while not object_list or not action_list:\n",
        "    try:\n",
        "      response = generate_chat_response(message=kw_extraction_template.substitute(gt_desc=desc))\n",
        "      response = response.choices[0][\"message\"][\"content\"].split(\"\\n\")\n",
        "\n",
        "      for line in response:\n",
        "        if \"object list\" in line.lower():\n",
        "          m = list_pattern.search(line)\n",
        "          object_list = m.group(0) if m else []\n",
        "          # object_list = ast.literal_eval(object_list)\n",
        "\n",
        "        if \"action list\" in line.lower():\n",
        "          m = list_pattern.search(line)\n",
        "          action_list = m.group(0) if m else []\n",
        "          # action_list = ast.literal_eval(action_list)\n",
        "\n",
        "      if not object_list or not action_list:\n",
        "        raise Exception\n",
        "    except:\n",
        "      print(\"FAILED TO EXTRACT OBJECT & ACTION LIST\")\n",
        "      print(response)\n",
        "      time.sleep(5)\n",
        "\n",
        "  result[\"object_list\"].append(object_list)\n",
        "  result[\"action_list\"].append(action_list)\n",
        "  time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG-ut5eaCgVA",
        "outputId": "4fc27b97-2653-4a0f-c207-8c4d9d81f6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword extraction: 100%|██████████| 100/100 [08:51<00:00,  5.32s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result[\"object_list\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2vgk5uy-ycH",
        "outputId": "ac367c6f-406f-4541-e2d2-3d21c047cdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## trial for using different temperature in gemini\n",
        "\n",
        "generationConfig = {\n",
        "    \"temperature\": 0.7,\n",
        "}\n",
        "\n",
        "model.generate_content([kw_hallucinate_template.substitute(\n",
        "                                                        object_list=object_list, \\\n",
        "                                                        action_list=action_list)],\n",
        "                                    generation_config=generationConfig).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G9yWepDZpXdZ",
        "outputId": "130a5b25-86d1-4b8b-9b45-b87eedab9469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Object list: [bird, nest, worm]\\nAction list: [fly, build, eat, turn]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## trial for using different temperature in chatgpt\n",
        "response = generate_chat_response(message=kw_hallucinate_template.substitute(\n",
        "                                                        object_list=result[\"object_list\"][11], \\\n",
        "                                                        action_list=result[\"action_list\"][11]),\n",
        "                                  temperature=0.7)\n",
        "response.choices[0][\"message\"][\"content\"].split(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1DI4_zfBWnF",
        "outputId": "b86d4efd-f775-4b39-8ee8-6037e77ef339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Given the constraints that the hallucinated object list must contain items unrelated to the original object list but able to perform the actions in the hallucinated action list, and that the hallucinated action list contains actions unrelated to the original action list but in their root forms, here are the hallucinated lists:',\n",
              " '',\n",
              " 'Hallucinated Object List:',\n",
              " '[fish, airplane, curtain, robot, tree, cyclist, bird, kite, snake, dancer]',\n",
              " '',\n",
              " 'Hallucinated Action List:',\n",
              " '[swim, fly, flutter, compute, grow, pedal, chirp, soar, slither, dance]']"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Hallucinated Keyword Generation"
      ],
      "metadata": {
        "id": "zQ8ZI5dHJn2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"hallucinated_object_list\"] = []\n",
        "result[\"hallucinated_action_list\"] = []"
      ],
      "metadata": {
        "id": "FfA-oGTNFtue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for object_list, action_list in tqdm(zip(result[\"object_list\"], result[\"action_list\"]), \"keyword hallucination generation\"):\n",
        "  # gemini\n",
        "  # response = model.generate_content([kw_hallucinate_template.substitute(\n",
        "  #                                                       object_list=object_list, \\\n",
        "  #                                                       action_list=action_list)])\n",
        "  # response = response.text.split(\"\\n\")\n",
        "\n",
        "  # h_object_list, h_action_list = [], []\n",
        "  # for line_idx, line in enumerate(response):\n",
        "  #   if \"object list\" in line.lower():\n",
        "  #     m = list_pattern.search(line)\n",
        "  #     h_object_list = m.group(0) if m else []\n",
        "  #   if \"action list\" in line.lower():\n",
        "  #     m = list_pattern.search(line)\n",
        "  #     h_action_list = m.group(0) if m else []\n",
        "\n",
        "    # for chatgpt\n",
        "  h_object_list, h_action_list = [], []\n",
        "  while not h_object_list or not h_action_list:\n",
        "    try:\n",
        "      response = generate_chat_response(message=kw_hallucinate_template.substitute(\n",
        "                                                              object_list=object_list, \\\n",
        "                                                              action_list=action_list),\n",
        "                                        temperature=0.7)\n",
        "      response = response.choices[0][\"message\"][\"content\"].split(\"\\n\")\n",
        "      for line_idx, line in enumerate(response):\n",
        "        if \"hallucinated object list\" in line.lower():\n",
        "          m = list_pattern.search(f\"{line} {response[line_idx+1]}\" if line_idx + 1 < len(response) else f\"{line}\")\n",
        "          h_object_list = m.group(0) if m else []\n",
        "\n",
        "        if \"hallucinated action list\" in line.lower():\n",
        "          m = list_pattern.search(f\"{line} {response[line_idx+1]}\" if line_idx + 1 < len(response) else f\"{line}\")\n",
        "          h_action_list = m.group(0) if m else []\n",
        "\n",
        "      if not h_object_list or not h_action_list:\n",
        "        raise Exception\n",
        "    except:\n",
        "      print(\"FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\")\n",
        "      print(response)\n",
        "      time.sleep(5)\n",
        "\n",
        "  if not h_object_list or not h_action_list:\n",
        "    print(\"failed to create hallucination lists\")\n",
        "    raise Exception\n",
        "\n",
        "  result[\"hallucinated_object_list\"].append(h_object_list)\n",
        "  result[\"hallucinated_action_list\"].append(h_action_list)\n",
        "  time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLm7nD3HHtdX",
        "outputId": "5156a525-b479-4ab9-85ee-b0984f915900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 14it [02:44, 12.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "['Hallucinated Object List:', '[bird, kite, boat, robot, garden]', '', 'Hallucinated Action List:', '[fly, glide, sail, compute, grow]', '', 'The hallucinated object list consists of items that are not related to girls, roller toys, walls, men, or areas. Similarly, the hallucinated action list consists of actions not related to pushing, holding onto, controlling, hitting, approaching, assisting, shifting, regaining attention, or touching. However, the hallucinated objects can perform the hallucinated actions (e.g., a bird can fly, a kite can glide, a boat can sail, a robot can compute, and a garden can grow).']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 46it [09:06, 11.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "['For the hallucinated lists, we need to choose objects and actions that are not present in the provided lists, while making sure that the objects can perform the actions in the hallucinated action list. ', '', 'Hallucinated Object List:', '[robot, artist, bird, computer, kite, bicycle, gardener]', '', 'Hallucinated Action List:', '[calculate, paint, fly, process, glide, pedal, plant]', '', 'These lists ensure that each object can perform the actions in the corresponding hallucinated action list, while avoiding overlap with the given lists.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 57it [11:18, 11.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "[\"To create a hallucinated object list that does not relate to the given object list, but whose items can perform actions in a corresponding hallucinated action list, we could consider a different set of objects and actions that are still logically coherent. Here's an example:\", '', 'Hallucinated object list:', '```plaintext', '[fish, airplane, camera, chef, curtain, dancer]', '```', '', 'Hallucinated action list:', '```plaintext', '[swim, fly, capture, cook, sway, perform]', '```', '', 'In this hallucinated list, each object could logically perform the corresponding action: fish can swim, airplanes can fly, cameras can capture images, chefs can cook, curtains can sway, and dancers can perform. The actions have been converted to their root form as requested.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rkeyword hallucination generation: 58it [11:38, 13.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "['Hallucinated Object List: [bird, kite, computer, tree, artist, fish, actor, telescope]', '', 'Hallucinated Action List: [fly, soar, compute, grow, paint, swim, perform, observe]', '', 'The hallucinated object list contains items not related to the given object list, but each object can perform the actions in the corresponding hallucinated action list. For example, a bird can fly, a kite can soar, a computer can compute, etc. The actions have been converted to their root form as requested.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 64it [12:53, 12.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "['Based on the criteria provided, here are the hallucinated lists:', '', 'Hallucinated Object List:', '[robot, airplane, bird, magician, curtain, book, garden, city]', '', 'Hallucinated Action List:', '[compute, fly, sing, vanish, unfold, read, grow, illuminate]', '', 'These lists ensure that the objects in the hallucinated object list can perform the actions in the hallucinated action list, and none of the hallucinated objects or actions are directly related to the given original lists.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 85it [17:07, 12.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "[\"Certainly! Keeping in mind that the hallucinated object list should be unrelated to the given object list but still correspond to the hallucinated action list, here's what I've come up with:\", '', 'Hallucinated Object List:', '[birds, kites, robots, dancers]', '', 'Hallucinated Action List:', '[fly, glide, compute, dance]', '', 'Each object on the hallucinated list can perform the actions described in the hallucinated action list. Birds can fly, kites can glide, robots can compute, and dancers can dance.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 99it [19:57, 11.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILED TO HALLUCINATED EXTRACT OBJECT & ACTION LIST\n",
            "['Here are the hallucinated lists that follow your instructions:', '', 'Hallucinated Object List:', '[fish, kite, computer, bird]', '', 'Hallucinated Action List:', '[swim, fly, compute, sing]', '', 'In this scenario, the objects in the hallucinated object list can perform the actions in the hallucinated action list. Fish can swim, kites can fly, computers can compute (process data), and birds can sing. These actions are converted to their base or root forms as requested.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "keyword hallucination generation: 100it [20:18, 12.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Incorrect Description Generation"
      ],
      "metadata": {
        "id": "wrOUsF8kJttp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for object_list, action_list in tqdm(zip(result[\"hallucinated_object_list\"], result[\"hallucinated_action_list\"]), \"generate incorrect description\"):\n",
        "  # gemini\n",
        "  # response = model.generate_content([incorrect_desc_template.substitute(\n",
        "  #                                                       object_list=object_list, \\\n",
        "  #                                                       action_list=action_list)])\n",
        "  # result[\"incorrect_description\"].append(response.text)\n",
        "\n",
        "  # chat-gpt\n",
        "  response = generate_chat_response(message=incorrect_desc_template.substitute(\n",
        "                                                          object_list=object_list, \\\n",
        "                                                          action_list=action_list),\n",
        "                                    temperature=0.7)\n",
        "  result[\"incorrect_description\"].append(response.choices[0][\"message\"][\"content\"].replace(\"\\n\", \" \"))\n",
        "\n",
        "  time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uCVQKViLdfX",
        "outputId": "8199d5a7-50e6-46b6-cbcf-3f16eba0563f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generate incorrect prompt: 100it [24:50, 14.91s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export it as CSV"
      ],
      "metadata": {
        "id": "v5ervOX3KCu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_desc_df[\"object_list\"] = result[\"object_list\"]\n",
        "filtered_desc_df[\"action_list\"] = result[\"action_list\"]\n",
        "filtered_desc_df[\"hallucinated_object_list\"] = result[\"hallucinated_object_list\"]\n",
        "filtered_desc_df[\"hallucinated_action_list\"] = result[\"hallucinated_action_list\"]\n",
        "filtered_desc_df[\"incorrect_description\"] = result[\"incorrect_description\"]\n",
        "# filtered_desc_df.to_csv(INCORRECT_DESC_PATH, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Y3AQotVgm8",
        "outputId": "272c9f63-461b-4441-f6c9-77c08ca50266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-154-41cb27707ea8>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_desc_df[\"object_list\"] = result[\"object_list\"]\n",
            "<ipython-input-154-41cb27707ea8>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_desc_df[\"action_list\"] = result[\"action_list\"]\n",
            "<ipython-input-154-41cb27707ea8>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_desc_df[\"hallucinated_object_list\"] = result[\"hallucinated_object_list\"]\n",
            "<ipython-input-154-41cb27707ea8>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_desc_df[\"hallucinated_action_list\"] = result[\"hallucinated_action_list\"]\n",
            "<ipython-input-154-41cb27707ea8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_desc_df[\"incorrect_description\"] = result[\"incorrect_description\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INCORRECT_DESC_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M6py4oiggyZJ",
        "outputId": "dd843c4f-fbba-447f-9972-82fdd23ea098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/Grounded Language Processing [146078]/Projects/incorrect_description.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_01im9s3llt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}